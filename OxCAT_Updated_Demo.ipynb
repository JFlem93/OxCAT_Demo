{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbb2a72",
   "metadata": {},
   "source": [
    "## Oxford Configurable Algorithm Tool (OxCAT) - Eyes Closed (Alpha) Demo\n",
    "\n",
    "This Jupyter Notebook integrates tools intended for setting up the configuration file for DyNeuMo-2.\n",
    "\n",
    "User's should run each cell as specified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4bf59",
   "metadata": {
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "# Run cells by clicking the run button in the toolbar\n",
    "# Load modules\n",
    "# Data handling and analysis modules -\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import signal, io\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram, periodogram, lfilter, freqz, iirfilter\n",
    "\n",
    "# import multitaper_spectrogram function from the multitaper_spectrogram_python.py file\n",
    "from multitaper_spectrogram_python import multitaper_spectrogram, nanpow2db  \n",
    "\n",
    "# Plotting modules\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Interactive plotting packages - \n",
    "import holoviews as hv\n",
    "from holoviews import opts, streams\n",
    "from holoviews.plotting.links import DataLink\n",
    "from holoviews.selection import link_selections\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "hv.extension(\"bokeh\", logo=False)\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import column, gridplot, layout\n",
    "from bokeh.models import BoxZoomTool, PanTool, ResetTool, HoverTool, WheelPanTool\n",
    "from bokeh.models.formatters import PrintfTickFormatter\n",
    "from bokeh.io import show, curdoc, export_svgs, export_png\n",
    "\n",
    "# For representing a datetime\n",
    "from datetime import datetime\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "# Import function for loading the DyNeuMo LFP data\n",
    "from read_Dyneumo_LFP_Format import read_Dyneumo_LFP_Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7132c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze | findstr numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stream = os.popen('state show packages')\n",
    "output = stream.read()\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "installed_packages = pkg_resources.working_set\n",
    "installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)\n",
    "   for i in installed_packages])\n",
    "#print(installed_packages_list)\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for package in installed_packages_list:\n",
    "        f.write(package)\n",
    "        f.write('\\n')\n",
    "f.close()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06290a9",
   "metadata": {},
   "source": [
    "## Step 0 - Load the DyNeuMo-2 Data File \n",
    "\n",
    "Any data file that is to analysed using the pipeline must be compliant with the structure of DyNeuMo-2 data. The pipeline should only accepts csv files which adhere to the DyNeuMo data format. \n",
    "\n",
    "An example data file for demonstation is included in the github repository (alpha_Demo_No_Offset_DyNeuMo_Format.csv). Download this data set, put it in your directory where this notebook is located and load by entering it's filepath in the text input field below when you run the next cell. Click the load data to subsequently load the specified file before moving on further in the workflow.\n",
    "\n",
    "Example filepath where the data file is saved in the desktop folder - \n",
    "C:/Users/../../Desktop/alpha_Demo_No_Offset_DyNeuMo_Format.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d08488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data tool - \n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd().replace('\\\\', '/')\n",
    "\n",
    "# Panels for loading the data file\n",
    "input_Filepath_Text = pn.widgets.TextInput(name='DyNeuMo-2 Data Filepath', value='', placeholder='Enter filepath here ...', width=600, align='end')\n",
    "load_Data_Button = pn.widgets.Button(name='Load Data', button_type='primary', width=100, align='end')\n",
    "\n",
    "# Define dictionary for storing the loaded data\n",
    "LFP_Data = {}\n",
    "\n",
    "def on_Load_Data_Button_Clicked(b):\n",
    "    \n",
    "    loaded_filename = input_Filepath_Text.value\n",
    "    loaded_filename.replace('\\\\', '/')\n",
    "                                                        \n",
    "    # Check if file exists\n",
    "    #if os.path.isfile(input_Filepath_Text.value):\n",
    "    if os.path.isfile(loaded_filename):\n",
    "        \n",
    "        #try: \n",
    "        # Load the data - need to pass the mark as a input\n",
    "        lfp = read_Dyneumo_LFP_Format(input_Filepath_Text.value, 2)\n",
    "\n",
    "        # Convert the raw LFP to a dataset\n",
    "        raw_LFP_data = {'Time': lfp['t'], 'Voltage': lfp['x']/1e-6}\n",
    "        raw_LFP_dataframe = pd.DataFrame(data=raw_LFP_data)\n",
    "        LFP_Data['raw_LFP_Data'] = raw_LFP_dataframe\n",
    "        LFP_Data['sampling_Frequency'] = lfp['Fs']\n",
    "        \n",
    "        # Calculate the signal spectrogram\n",
    "        # Original Implementation -\n",
    "        #frequency, time, Sxx = spectrogram(raw_LFP_data['Voltage'], LFP_Data['sampling_Frequency'])\n",
    "        #LFP_Spectrogram_ds = hv.Dataset((time, frequency, np.log10(Sxx)), ['Time', 'Frequency'], 'dB/Hz')\n",
    "        #LFP_Data['raw_LFP_Spectrogram'] = LFP_Spectrogram_ds\n",
    "        \n",
    "        # Multitaper Implementation - \n",
    "        frequency_range = [0, 40]  # Limit frequencies from 0 to 25 Hz\n",
    "        time_bandwidth = 2  # Set time-half bandwidth\n",
    "        num_tapers = int(time_bandwidth*2 - 1)  # Set number of tapers (optimal is time_bandwidth*2 - 1)\n",
    "        window_params = [4, 1]  # Window size is 4s with step size of 1s\n",
    "        min_nfft = 0  # No minimum nfft\n",
    "        detrend_opt = 'constant'  # detrend each window by subtracting the average\n",
    "        multiprocess = True  # use multiprocessing\n",
    "        n_jobs = 3  # use 3 cores in multiprocessing\n",
    "        weighting = 'unity'  # weight each taper at 1\n",
    "        plot_on = False  # plot spectrogram\n",
    "        clim_scale = False # do not auto-scale colormap\n",
    "        verbose = False  # print extra info\n",
    "        xyflip = False  # do not transpose spect output matrix\n",
    "\n",
    "        # Compute the multitaper spectrogram\n",
    "        Sxx, time, frequency = multitaper_spectrogram(raw_LFP_data['Voltage'], LFP_Data['sampling_Frequency'], frequency_range, time_bandwidth, num_tapers, window_params, min_nfft, detrend_opt, multiprocess, n_jobs,\n",
    "                                                       weighting, plot_on, clim_scale, verbose, xyflip)\n",
    "        LFP_Spectrogram_ds = hv.Dataset((time, frequency, nanpow2db(Sxx)), ['Time', 'Frequency'], 'dB')\n",
    "        LFP_Data['raw_LFP_Spectrogram'] = LFP_Spectrogram_ds\n",
    "        dx = time[1] - time[0]\n",
    "        dy = frequency[1] - frequency[0]\n",
    "        LFP_Data['Spectrogram_dx'] = dx\n",
    "        LFP_Data['Spectrogram_dy'] = dy\n",
    "\n",
    "    else:\n",
    "        # Message to let user know the file was not loaded \n",
    "        input_Filepath_Text.value = \"Error - Can't find file, please check the input filename or filepath\"\n",
    "\n",
    "# Connect the button widgets to their respective functions\n",
    "load_Data_Button.on_click(on_Load_Data_Button_Clicked)\n",
    "\n",
    "# Layout of the widgets\n",
    "load_Data_Row = pn.Row(input_Filepath_Text, load_Data_Button)\n",
    "load_Data_Row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf790ead",
   "metadata": {},
   "source": [
    "## Step 1 - Inspect the Loaded Data\n",
    "\n",
    "If you have input the data file correctly in the text input field above and clicked the 'Load Data' button your data should now be correctly load in the notebook. Run the next cell to get a preliminary view of your loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=600, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%%opts Histogram [height=200 width=300, tools=['hover'], active_tools=[]]\n",
    "\n",
    "# Set x-limits for time series\n",
    "time_series_x_limits = (LFP_Data['raw_LFP_Data']['Time'].to_numpy()[0]+LFP_Data['Spectrogram_dx'] , LFP_Data['raw_LFP_Data']['Time'].to_numpy()[-1]-LFP_Data['Spectrogram_dx'])\n",
    "\n",
    "# Plot the data as a curve\n",
    "raw_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'Voltage')\n",
    "\n",
    "# Calculate the histogram of the raw LFP\n",
    "hist_frequencies, hist_edges = np.histogram(LFP_Data['raw_LFP_Data']['Voltage'], 50)\n",
    "\n",
    "# Normalize the histogram frequency as a percentage of the signal length\n",
    "percent_hist_frequencies = 100*(hist_frequencies/len(LFP_Data['raw_LFP_Data']['Voltage']))\n",
    "\n",
    "# Normalized histogram plot\n",
    "LFP_histogram = hv.Histogram((hist_edges, percent_hist_frequencies)).opts(xlabel='Signal Level (uV)', ylabel='Signal Distribution (%)')\n",
    "\n",
    "# Plot the spectrogram for the signal\n",
    "spectrogram_Plot = LFP_Data['raw_LFP_Spectrogram'].to(hv.Image, ['Time', 'Frequency']).opts(cmap='Jet', colorbar=True)\n",
    "\n",
    "# Plot the time series and histogram\n",
    "raw_signal_Plots = hv.Layout((raw_LFP_Trace).opts(xlim=time_series_x_limits, xlabel='Time (s)', ylabel='Voltage (uV)', color='blue', title=\"Raw LFP\", fontscale=1.2, xformatter='%d', yformatter='%.1f', width=600)  + (LFP_histogram).opts(color='blue', ylim=(0, 10), title=\"LFP Histogram\", fontscale=1.2, xformatter='%.1f', yformatter='%d', width=300))\n",
    "raw_signal_Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3f48",
   "metadata": {},
   "source": [
    "## Step 2 - Event Data Labelling\n",
    "\n",
    "Run the next two cells below to generate the data labelling tool. From the dropdown menu select whether the segment of data you want to highlight is an 'event' or 'not_event'. The click the box_select tool from the figure toolbar (its the box with a plus in its lower right corner symbol'). Use the box_select tool to highlight your regions of interest. The region of interest will show two dashed red lines on either side of it when highlighted. Click the 'Label Segment' button to label the segment as you wish. \n",
    "\n",
    "Once you have labelled all the segments you want you can move on to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900 tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%opts Image  [height=300 width=900, tools=['box_select', 'hover'], active_tools=[]]\n",
    "\n",
    "# Inspect the spectrogram\n",
    "# Plot the time series and spectrogram\n",
    "time_frequency_layout = hv.Layout((raw_LFP_Trace).opts(title=\"Raw LFP\", fontscale=1.2, xaxis=None, xlim=time_series_x_limits)  + (spectrogram_Plot).opts(xlim=time_series_x_limits, title=\"LFP Spectrogram\", fontscale=1.2)).cols(1)\n",
    "time_frequency_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331302f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900, tools=['box_select', 'hover'], active_tools=['box_select']]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%%opts Image  [height=300 width=900, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts VLine (color='red' line_dash='dashed')\n",
    "\n",
    "# Define region of interest indices as a list\n",
    "roi_indices = [-1, -1]\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def mark_ROI(boundsx):\n",
    "    \n",
    "    # Set roi_indices as a global variable\n",
    "    global roi_indices \n",
    "    \n",
    "    # Set the roi indices to those input\n",
    "    roi_indices = [boundsx[0], boundsx[1]]\n",
    "    \n",
    "    # Highlight the roi as vertical lines\n",
    "    start_line = hv.VLine(boundsx[0]).opts(color='red', line_dash='dashed')\n",
    "    end_line = hv.VLine(boundsx[1]).opts(color='red', line_dash='dashed')\n",
    "    roi_markers = start_line * end_line\n",
    "    \n",
    "    return roi_markers\n",
    "\n",
    "# Define a dynamic map for highlighting the bounds of the region of interest\n",
    "roi = hv.DynamicMap(mark_ROI, streams=[streams.BoundsX(source=spectrogram_Plot, boundsx=(-1,-1))])\n",
    "\n",
    "# Add checkbox and button for data labelling\n",
    "dropdown_Label_Select = pn.widgets.Select(options=['event','not_event'], name='Data Segment Label')\n",
    "label_Segment_Button = pn.widgets.Button(name='Label Segment', button_type='primary', width=100, align='end')\n",
    "text = pn.widgets.TextInput(value='Data Segment - ', align='end')\n",
    "\n",
    "# Define dataframe for the regions of interest\n",
    "roi_segments_df = pd.DataFrame(columns=['Event_Type', 'Start_Time', 'End_Time'])\n",
    "\n",
    "# For loading events\n",
    "load_Events_Input_Filepath_Text = pn.widgets.TextInput(name='Event Labels Filepath', value='', placeholder='Enter filepath here ...', width=600, align='end')\n",
    "load_Event_Labels_Button = pn.widgets.Button(name='Load Events', button_type='primary', width=100, align='end')\n",
    "\n",
    "input_labels = []\n",
    "\n",
    "# Function to load events from file highlighted segment to dataframe\n",
    "def load_Events(event):\n",
    "    \n",
    "    # Define access to global variable elements\n",
    "    global roi_segments_df\n",
    "    global roi_indices \n",
    "    global input_labels\n",
    "    \n",
    "    # load the specified labels file\n",
    "    event_labels_file = load_Events_Input_Filepath_Text.value\n",
    "    event_labels_file.replace('\\\\', '/')\n",
    "    event_labels_data = np.loadtxt(event_labels_file, delimiter=',')\n",
    "    \n",
    "    # For debugging - \n",
    "    input_labels = event_labels_data\n",
    "    \n",
    "    # Check for when the signal changes - 0 -> 1 for start of event, 1 -> 0 for end of event\n",
    "    delta_event_labels = np.diff(event_labels_data, prepend=np.array([0]))\n",
    "    event_start_indices = np.where(delta_event_labels == 1)[0]\n",
    "    event_end_indices = np.where(delta_event_labels == -1)[0]\n",
    "    \n",
    "    # Append event labels to dataframe\n",
    "    for event_id in np.arange(0, len(event_start_indices), 1):\n",
    "        \n",
    "        # Add the new data segment to the roi segments dataframe\n",
    "        new_row = {'Event_Type': 'event', 'Start_Time': LFP_Data['raw_LFP_Data']['Time'][event_start_indices[event_id]], 'End_Time': LFP_Data['raw_LFP_Data']['Time'][event_end_indices[event_id]]}\n",
    "        roi_segments_df = roi_segments_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    # Update text box text \n",
    "    text.value = 'Loaded Events!'\n",
    "    \n",
    "    return text.value\n",
    "\n",
    "# Function to append highlighted segment to dataframe\n",
    "def append_segment(event):\n",
    "    \n",
    "    # Define access to global variable elements\n",
    "    global roi_segments_df\n",
    "    global roi_indices \n",
    " \n",
    "    # Add the new data segment to the roi segments dataframe\n",
    "    new_row = {'Event_Type': dropdown_Label_Select.value, 'Start_Time': roi_indices[0], 'End_Time': roi_indices[1]}\n",
    "    roi_segments_df = roi_segments_df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # Update text box text \n",
    "    text.value = '{0} = ({1} - {2}) s'.format(dropdown_Label_Select.value, roi_indices[0], roi_indices[1])\n",
    "    \n",
    "    return text.value\n",
    "\n",
    "# Trigger when button is clicked\n",
    "label_Segment_Button.on_click(append_segment)\n",
    "load_Event_Labels_Button.on_click(load_Events)\n",
    "\n",
    "# Put data panels together\n",
    "time_frequency_events_layout = pn.Column(hv.Layout((raw_LFP_Trace * roi).opts(height=200, width=900, title=\"Raw LFP\", fontscale=1.2, xaxis=None) + (spectrogram_Plot * roi).opts(height=300, width=900, title=\"LFP Spectrogram\", fontscale=1.2)).cols(1), pn.Row(load_Events_Input_Filepath_Text, load_Event_Labels_Button), pn.Row(dropdown_Label_Select, label_Segment_Button, text))\n",
    "annotation_tool_card = pn.Card(time_frequency_events_layout, title='Event Annotation Tool', background='WhiteSmoke')\n",
    "annotation_tool_card\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b4f72",
   "metadata": {},
   "source": [
    "## Step 3 - View Event Labels\n",
    "\n",
    "Run the next cell below to generate a table to summarize your label data segments. Labels can be deleted if they are selected and the 'delete Annotations' button is clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data frame \n",
    "event_Annotations_df = pn.widgets.DataFrame(roi_segments_df, name='Event Annotations', auto_edit=True)\n",
    "\n",
    "def stream_data():\n",
    "    stream_df = pd.DataFrame(roi_segments_df, name='DataFrame')\n",
    "    event_Annotations_df.stream(stream_df)\n",
    "    \n",
    "pn.state.add_periodic_callback(stream_data, period=1000, count=5)\n",
    "\n",
    "delete_Segments_Button = pn.widgets.Button(name='Delete Annotation(s)', button_type='primary', width=100, align='end')\n",
    "\n",
    "def delete_annotations(event):\n",
    "    \n",
    "    # Define access to global variable elements\n",
    "    global roi_segments_df\n",
    "    global roi_indices \n",
    " \n",
    "    # Get the selected dataframe entry from the table\n",
    "    selected_entry_ids = event_Annotations_df.selection\n",
    "    \n",
    "    roi_segments_df.drop(selected_entry_ids, axis=0, inplace=True)\n",
    "    \n",
    "    return roi_segments_df\n",
    "\n",
    "# Link button click to deleting the entries from the table\n",
    "delete_Segments_Button.on_click(delete_annotations)\n",
    "\n",
    "# Now plot the panels below\n",
    "annotation_Viewer_Pane = pn.Column(event_Annotations_df, delete_Segments_Button)\n",
    "annotation_Viewer_Pane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6ee1f",
   "metadata": {},
   "source": [
    "## Step 4 - View Event Power Spectra\n",
    "\n",
    "Run the cell below to generate the power spectra for the event vs. non_event class segments that were labelled. If you are happy with how the power spectra look you need to click the 'Export Labels' button before moving on to the next part of the workflow. Enter a filename in the text input field for the labels of the data to be written to before clicking the 'Export Labels' button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a6157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve  [height=450 width=650, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts VLine (color='black' line_dash='dashed')\n",
    "\n",
    "# Get the event labels\n",
    "event_Labels = pd.unique(roi_segments_df['Event_Type'])\n",
    "\n",
    "# Dictionary for storing the labelled data snippets\n",
    "event_segments = {}\n",
    "max_data_segment_length = 0\n",
    "\n",
    "# Set up array of potential data labels\n",
    "user_defined_labels = np.zeros(len(LFP_Data['raw_LFP_Data']['Time']))\n",
    "\n",
    "# Parse the roi dataframe into a dictionary for each event\n",
    "for event_Label in event_Labels:\n",
    "    \n",
    "    # Extract the start and end times for each event roi as a list\n",
    "    event_dataframes = {}\n",
    "    event_table = roi_segments_df.loc[roi_segments_df['Event_Type'] == event_Label][['Start_Time', 'End_Time']]\n",
    "    event_dataframes[event_Label] = event_table.values.tolist()\n",
    "    \n",
    "    # Add event snippet to the dictionary \n",
    "    event_segments[event_Label] = []\n",
    "    \n",
    "    # Increment through each event to pull the associated snipped of data\n",
    "    for event_index in np.arange(0, len(event_dataframes[event_Label]), 1):\n",
    "    \n",
    "        snippet_start_id = (LFP_Data['raw_LFP_Data']['Time'] - event_dataframes[event_Label][event_index][0]).abs().argsort()[0]\n",
    "        snippet_end_id = (LFP_Data['raw_LFP_Data']['Time'] - event_dataframes[event_Label][event_index][1]).abs().argsort()[0]\n",
    "\n",
    "        # if event_Label is 'event' then set indices identified to 1\n",
    "        if event_Label == 'event':\n",
    "            user_defined_labels[snippet_start_id:snippet_end_id] = 1\n",
    "        \n",
    "        # Pull this snippet then from the original data dataframe\n",
    "        event_data_snippet = {'Time': LFP_Data['raw_LFP_Data']['Time'][snippet_start_id:snippet_end_id] , 'Voltage': LFP_Data['raw_LFP_Data']['Voltage'][snippet_start_id:snippet_end_id]}\n",
    "\n",
    "        # Add event snippet to the dictionary \n",
    "        event_segments[event_Label].append(event_data_snippet)\n",
    "\n",
    "        # Also calculate the length of the segment so can zero to length of longest segment later for PSD\n",
    "        if len(event_data_snippet['Time']) > max_data_segment_length:\n",
    "            max_data_segment_length = len(event_data_snippet['Time'])\n",
    "        \n",
    "        \n",
    "# Function to append highlighted segment to dataframe\n",
    "def calculate_PSD(x, Fs, max_segment_length):\n",
    "    \n",
    "    if len(x) < max_segment_length:\n",
    "        x = np.hstack((x, np.zeros(max_segment_length - len(x))))\n",
    "        \n",
    "    f, Pxx_den = signal.welch(x, Fs, nperseg=1024)\n",
    "    \n",
    "    return f, Pxx_den\n",
    "        \n",
    "def calculate_Event_PSDs(event_segments, event_Labels, Fs, max_segment_length):\n",
    "    \n",
    "    # Create dictionary for the storing the PSD for each event\n",
    "    event_PSDs = {}\n",
    "    \n",
    "    # Go through the event labels\n",
    "    for event_Label in event_Labels:\n",
    "        \n",
    "        # Add event label to the PSD dictionary \n",
    "        event_PSDs[event_Label] = []\n",
    "    \n",
    "        # Increment through each event snippet and calculate it's PSD\n",
    "        for index in np.arange(0, len(event_segments[event_Label]), 1):\n",
    "            \n",
    "            # Calculate the event PSD\n",
    "            snippet_f, snippet_Pxx_den = calculate_PSD(event_segments[event_Label][index]['Voltage'], Fs, max_segment_length)\n",
    "            \n",
    "            # Normalize the PSD by the total power for the snippet across the frequencies\n",
    "            snippet_Pxx_den_dB = 10*np.log10(snippet_Pxx_den)\n",
    "            snippet_Pxx_den_dB\n",
    "            total_Pxx_dB = np.sum(snippet_Pxx_den_dB)\n",
    "            \n",
    "            # Pull this snippet then from the original data dataframe\n",
    "            event_PSD = {'Frequency': snippet_f, 'Pxx': snippet_Pxx_den_dB}\n",
    "        \n",
    "            # Add event snippet to the dictionary \n",
    "            event_PSDs[event_Label].append(event_PSD)\n",
    "            \n",
    "    return event_PSDs\n",
    "\n",
    "# Calculate all the event PSDs\n",
    "event_PSDs = calculate_Event_PSDs(event_segments, event_Labels, LFP_Data['sampling_Frequency'], max_data_segment_length)\n",
    "\n",
    "# Generate the cumulative PSDs for each event\n",
    "event_cumulative_PSDs = {}\n",
    "\n",
    "for event_Label in event_Labels: \n",
    "    event_PSD_HoloMap = hv.HoloMap({i: hv.Curve(event_PSDs[event_Label][i], 'Frequency', 'Pxx') for i in range(len(event_PSDs[event_Label]))})\n",
    "    cumulative_event_PSD = event_PSD_HoloMap.collapse(function=np.mean, spreadfn=np.std)\n",
    "    event_cumulative_PSDs[event_Label] = cumulative_event_PSD\n",
    "    \n",
    "# Plot the cumulative power spectra  \n",
    "for index in np.arange(0, len(event_cumulative_PSDs), 1):\n",
    "    if index == 0:\n",
    "#        cumulative_PSD_Figure = hv.Spread(event_cumulative_PSDs[event_Labels[index]]) * (hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label))\n",
    "        cumulative_PSD_Figure = hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "    else:\n",
    "#        cumulative_PSD_Figure = cumulative_PSD_Figure * hv.Spread(event_cumulative_PSDs[event_Labels[index]]) * hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "        cumulative_PSD_Figure = cumulative_PSD_Figure * hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "    \n",
    "# Define region of interest indices as a list\n",
    "frequency_band_roi_indices = [-1, -1]\n",
    "\n",
    "# Function definition for marking the frequency band region of interest\n",
    "def mark_Frequency_Band_ROI(boundsx):\n",
    "    \n",
    "    # Set roi_indices as a global variable\n",
    "    global frequency_band_roi_indices \n",
    "    \n",
    "    # Set the roi indices to those input\n",
    "    frequency_band_roi_indices = [boundsx[0], boundsx[1]]\n",
    "    \n",
    "    # Highlight the roi as vertical lines\n",
    "    start_line = hv.VLine(boundsx[0])\n",
    "    end_line = hv.VLine(boundsx[1])\n",
    "    frequency_Band_roi_markers = start_line * end_line\n",
    "    \n",
    "    return frequency_Band_roi_markers    \n",
    "\n",
    "# Set up dynamic map for marking the frequency band of interest\n",
    "frequency_Band_roi = hv.DynamicMap(mark_Frequency_Band_ROI, streams=[streams.BoundsX(source=cumulative_PSD_Figure, boundsx=(-1,-1))])\n",
    "\n",
    "# Plot the cumulative Power Spectra for the events\n",
    "#cumulative_PSD_with_ROI_Figure = (cumulative_PSD_Figure * frequency_Band_roi).opts(xlim=(0,LFP_Data['sampling_Frequency']/2.0), ylabel='dB/Hz', xlabel='Frequency (Hz)', title=\"Cumulative Event Power Spectra\", fontscale=1.5, show_legend=True)\n",
    "#cumulative_PSD_with_ROI_Figure = (cumulative_PSD_Figure * frequency_Band_roi).opts(xlim=(0,40), ylim=(-200, -120), ylabel='dB', xlabel='Frequency (Hz)', title=\"Cumulative Event Power Spectra\", fontscale=1.5, show_legend=True)\n",
    "cumulative_PSD_with_ROI_Figure = (cumulative_PSD_Figure * frequency_Band_roi).opts(xlim=(0,40), ylabel='dB', xlabel='Frequency (Hz)', title=\"Cumulative Event Power Spectra\", fontscale=1.5, show_legend=True)\n",
    "\n",
    "# Add text box and buttons for exporting data labels and bandpass cutoff frequencies\n",
    "event_Labels_filename = pn.widgets.TextInput(value='', placeholder='Enter Event Labels Filename ...', width=500, align='end')\n",
    "export_Data_Labels_Button = pn.widgets.Button(name='Export Labels', button_type='primary', width=100, align='end')\n",
    "load_Data_Labels_Button = pn.widgets.Button(name='Load Labels', button_type='primary', width=100, align='end')\n",
    "extract_Cutoff_Frequencies_Button = pn.widgets.Button(name='Extract Bandpass Fc', button_type='primary', width=100, align='end')\n",
    "\n",
    "# Function to save the data labels to a csv file\n",
    "def export_Data_Labels(event):\n",
    "    \n",
    "    # Save the user defined labels array of 1s (event) and 0s (not_event) to a csv file\n",
    "    np.savetxt(event_Labels_filename.value, user_defined_labels, delimiter=\",\")\n",
    "    LFP_Data['raw_LFP_Data']['Data_Labels'] = user_defined_labels\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "export_Data_Labels_Button.on_click(export_Data_Labels)\n",
    "\n",
    "# Function to load the data labels to a csv file\n",
    "def load_Data_Labels(event):\n",
    "    \n",
    "    global LFP_Data\n",
    "    \n",
    "    # Load the user defined labels array of 1s (event) and 0s (not_event) to a csv file\n",
    "    label_filename = event_Labels_filename.value\n",
    "    label_filename.replace('\\\\', '/')\n",
    "    user_defined_labels = np.loadtxt(label_filename, delimiter=\",\")\n",
    "    LFP_Data['raw_LFP_Data']['Data_Labels'] = user_defined_labels\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "load_Data_Labels_Button.on_click(load_Data_Labels)\n",
    "\n",
    "bandpass_cutoff_frequencies = [-1, -1]\n",
    "\n",
    "# Function to save the data labels to a csv file\n",
    "def extract_Cutoff_Frequencies(event):\n",
    "    \n",
    "    global bandpass_cutoff_frequencies\n",
    "    global frequency_band_roi_indices\n",
    "    \n",
    "    # Update the frequencies that'll be used for the bandpass filter\n",
    "    bandpass_cutoff_frequencies = [frequency_band_roi_indices[0], frequency_band_roi_indices[1]]\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "extract_Cutoff_Frequencies_Button.on_click(extract_Cutoff_Frequencies)\n",
    "\n",
    "psd_Inspector_Tool_Content = pn.Column(cumulative_PSD_with_ROI_Figure.opts(height=450, width=650), pn.Row(event_Labels_filename, load_Data_Labels_Button, export_Data_Labels_Button))\n",
    "\n",
    "psd_Inspector_Tool = pn.Card(psd_Inspector_Tool_Content, title='Event Power Spectra Viewer', background='WhiteSmoke')\n",
    "psd_Inspector_Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7018de1",
   "metadata": {},
   "source": [
    "# Step 5 - Filter Design Tool\n",
    "\n",
    "Note the frequency bands you are interested in from the PSD figure above. Run the next cell below to generate the filter design tool for configuring the signal processing chain configuration. Each stage can be enabled or disabled by clicking their corresponding radio button. Widgets are available for setting the parameters of the offset, bandpass and smooting filters. \n",
    "\n",
    "Once you are happy with your specified parameters click the 'Build Filters Button' to generate each stage as specified with the tool. \n",
    "\n",
    "After the stages are built you can then click the 'Run Signal Chain' button to run the input signal through the signal chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50797cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for tracking filter stages used\n",
    "filter_stage_options = {\"Offset_Filter\": False,\n",
    "                        \"Bandpass_Filter\": False, \n",
    "                        \"Rectifier\": False, \n",
    "                        \"Smoothing_Filter\": False}\n",
    "filter_stage_responses = {}\n",
    "\n",
    "# Variable for tracking the filter implementation used\n",
    "filter_DyNeuMo_Implementation = False\n",
    "\n",
    "# Offset filter widgets - \n",
    "offset_Filter_Group = pn.widgets.RadioButtonGroup(\n",
    "    name='Offset Filter Group', options=['Disable', 'Enable'], button_type='default')\n",
    "\n",
    "offset_Fc_select = pn.widgets.Select(name='Offset Fc (Hz):', options=['0.10', '0.19', '0.39', '0.78', '1.59', '3.24', '6.80', '15.30'])\n",
    "\n",
    "# Default filter parameters - for offset removal\n",
    "highpass_cutoff = -1        # high cutoff frequency\n",
    "highpass_filter_order = 2\n",
    "\n",
    "# Bandpass filter widgets - \n",
    "bandpass_Filter_Group = pn.widgets.RadioButtonGroup(\n",
    "    name='Bandpass Filter Group', options=['Disable', 'Enable'], button_type='default')\n",
    "\n",
    "bandpass_Fc_Range_Slider = pn.widgets.EditableRangeSlider(\n",
    "    name='Bandpass Fc: ', start=1, end=100, value=(0, 100),\n",
    "    step=1, format=PrintfTickFormatter(format='%.0f Hz'))\n",
    "\n",
    "# Default filter parameters\n",
    "bandpass_lowcut = -1\n",
    "bandpass_highcut = -1\n",
    "bandpass_filter_order = 4\n",
    "\n",
    "# Rectification widget - \n",
    "rectification_Group = pn.widgets.RadioButtonGroup(\n",
    "    name='Rectification Group', options=['Disable', 'Enable'], button_type='default')\n",
    "\n",
    "# Smoothing filter widgets - \n",
    "smoothing_Filter_Group = pn.widgets.RadioButtonGroup(\n",
    "    name='Smoothing Filter Group', options=['Disable', 'Enable'], button_type='default')\n",
    "\n",
    "smoothing_Fc_Slider = pn.widgets.FloatSlider(\n",
    "    name='Smoothing Fc:', start=0.25, end=5.0, step=0.25, value=1.0, \n",
    "    format=PrintfTickFormatter(format='%.2f Hz'))\n",
    "\n",
    "# Default filter parameters - for envelope extraction\n",
    "lowpass_cutoff = -1        # low cutoff frequency\n",
    "lowpass_filter_order = 2\n",
    "\n",
    "# Build filters widgets - \n",
    "# Two filter implementations\n",
    "#       1) For the DyNeuMo Filter Implementation\n",
    "#       2) For a generic python Filter Implementation\n",
    "build_Filter_Group = pn.widgets.RadioButtonGroup(\n",
    "    name='Filter Implementation Group', options=['Generic', 'DyNeuMo'], button_type='default')\n",
    "build_Filters_Button = pn.widgets.Button(name='Build DyNeuMo Filters', button_type='primary', width=100)\n",
    "\n",
    "# Run Signal Chain widgets - \n",
    "run_Signal_Chain_Button = pn.widgets.Button(name='Run Signal Chain', button_type='primary', width=100)\n",
    "\n",
    "# Filter stage specification string for DyNeuMo-2\n",
    "filter_configuration_string = \"\"\n",
    "\n",
    "# Dictionary for storing the generically generated filter coefficients\n",
    "generic_filter_coefficients = {}\n",
    "\n",
    "# Make a dataframe for the cutoff frequencies\n",
    "filter_stage_cutoff_frequencies = {}\n",
    "\n",
    "# Function for generating python implementations of the filter co-efficents\n",
    "def iir_butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = iirfilter(order, [low, high], btype='band', analog=False, ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "# Function for generating filter co-efficients\n",
    "def iir_butter_lowpass(lowcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    b, a = iirfilter(order, low, btype='low', analog=False, ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "# Function for generating filter co-efficients\n",
    "def iir_butter_highpass(highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    high = highcut / nyq\n",
    "    b, a = iirfilter(order, high, btype='high', analog=False, ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "def build_Filters(event):\n",
    "    \n",
    "    # Variables for tracking the filter stages used\n",
    "    global filter_stage_options\n",
    "    \n",
    "    # Variable for tracking the filter implementation used\n",
    "    global filter_DyNeuMo_Implementation \n",
    "    \n",
    "    # Filter parameter specification variables\n",
    "    global highpass_cutoff\n",
    "    global highpass_filter_order\n",
    "    \n",
    "    global bandpass_lowcut\n",
    "    global bandpass_highcut\n",
    "    global bandpass_filter_order\n",
    "    \n",
    "    global lowpass_cutoff\n",
    "    global lowpass_filter_order\n",
    "    \n",
    "    # Define string for specifying the flags for the filter stages to be implemented\n",
    "    global filter_configuration_string\n",
    "    filter_configuration_string = \"\"\n",
    "    \n",
    "    global LFP_Data\n",
    "    \n",
    "    global generic_filter_coefficients\n",
    "    \n",
    "    # Go through each filter widget and check if it is enabled\n",
    "    if offset_Filter_Group.value == 'Enable':\n",
    "        # Update the corresponding filter cutoff frequency \n",
    "        highpass_cutoff = float(offset_Fc_select.value)\n",
    "        \n",
    "        # Track that the offset filter is enabled\n",
    "        filter_stage_options[\"Offset_Filter\"] = True\n",
    "    \n",
    "    else:\n",
    "        # Track that the offset filter is disabled\n",
    "        filter_stage_options[\"Offset_Filter\"] = False\n",
    "        \n",
    "        # Remove coefficients from dictionary\n",
    "        if \"Offset_Filter\" in generic_filter_coefficients:\n",
    "            del generic_filter_coefficients[\"Offset_Filter\"]\n",
    "        \n",
    "    if bandpass_Filter_Group.value == 'Enable':\n",
    "        # Update the corresponding filter cutoff frequency \n",
    "        bandpass_lowcut = float(bandpass_Fc_Range_Slider.value[0])\n",
    "        bandpass_highcut = float(bandpass_Fc_Range_Slider.value[1])\n",
    "        \n",
    "        # Track that the bandpass filter is enabled\n",
    "        filter_stage_options[\"Bandpass_Filter\"] = True\n",
    "    \n",
    "    else:\n",
    "        # Track that the bandpass filter is disabled\n",
    "        filter_stage_options[\"Bandpass_Filter\"] = False\n",
    "        \n",
    "        # Remove coefficients from dictionary\n",
    "        if \"Bandpass_Filter\" in generic_filter_coefficients:\n",
    "            del generic_filter_coefficients[\"Bandpass_Filter\"]\n",
    "    \n",
    "    if rectification_Group.value == 'Enable':\n",
    "        # Track that the rectifier is enabled\n",
    "        filter_stage_options[\"Rectifier\"] = True\n",
    "    \n",
    "    else:\n",
    "        # Track that the rectifier is disabled\n",
    "        filter_stage_options[\"Rectifier\"] = False\n",
    "    \n",
    "    if smoothing_Filter_Group.value == 'Enable':\n",
    "        # Update the corresponding filter cutoff frequency \n",
    "        lowpass_cutoff = float(smoothing_Fc_Slider.value)\n",
    "        \n",
    "        # Track that the Smoothing filter is enabled\n",
    "        filter_stage_options[\"Smoothing_Filter\"] = True\n",
    "    \n",
    "    else:\n",
    "        # Track that the Smoothing filter is disabled\n",
    "        filter_stage_options[\"Smoothing_Filter\"] = False\n",
    "        \n",
    "        # Remove coefficients from dictionary\n",
    "        if \"Smoothing_Filter\" in generic_filter_coefficients:\n",
    "            del generic_filter_coefficients[\"Smoothing_Filter\"]\n",
    "    \n",
    "    # Now check whether the implementation is generic or for the DyNeuMo\n",
    "    if filter_DyNeuMo_Implementation == True:\n",
    "        \n",
    "        # Build the string to specify the filter configuration for Robert's program\n",
    "        pass\n",
    "        \n",
    "        # Example string\n",
    "        # '/filter_tool.exe --offset 0.1 --bandpass 4 18 22 --abs --movexp f 0.1 --lowpass 2 5 --fs 625'\n",
    "        \n",
    "        #path_to_filter_executable = 'C:/Users/ndcm1133/OneDrive - Nexus365/Desktop/DyNeuMo_Software/DyNeuMo_Pipeline/DyNeuMo_2_Pipeline/Robert_DyNeuMo_Filter_Tool'\n",
    "        #result = subprocess.run(\n",
    "        #    path_to_filter_executable+'/filter_tool.exe --offset 0.1 --bandpass 4 18 22 --abs --movexp f 1 --lowpass 2 5 --fs 625', capture_output=True\n",
    "        #)\n",
    "\n",
    "        ## Convert the subprocess result to a string that can be loaded as json\n",
    "        #filter_parameters_string = result.stdout.decode('utf-8')\n",
    "\n",
    "        ## Load the json as a python dictionary\n",
    "        #filter_parameters = json.loads(filter_parameters_string)\n",
    "\n",
    "        #filter_parameters['coeffs'][\"0\"][\"offset_shift\"]\n",
    "    \n",
    "    else:    \n",
    "        # Make filter response dataframe \n",
    "        global filter_stage_responses\n",
    "        filter_stage_responses = {}\n",
    "        \n",
    "        # Make dataframe for storing the cutoff frequencies\n",
    "        global filter_stage_cutoff_frequencies\n",
    "        filter_stage_cutoff_frequencies = {}\n",
    "        \n",
    "        # Loop of the different filter stages\n",
    "        for filter_stage_key in filter_stage_options:\n",
    "            \n",
    "            # Check if the offset filter is implemented and calculate filter response if so\n",
    "            if ((filter_stage_key == \"Offset_Filter\") and (filter_stage_options[filter_stage_key] == True)):\n",
    "                \n",
    "                # Calculate highpass frequency response \n",
    "                highpass_b, highpass_a = iir_butter_highpass(highpass_cutoff, LFP_Data['sampling_Frequency'], order=highpass_filter_order)\n",
    "                highpass_w, highpass_h = freqz(highpass_b, highpass_a, worN=2000)\n",
    "                \n",
    "                # Add the coefficients to the filter coefficient dictionary\n",
    "                generic_filter_coefficients['Offset_Filter'] = {}\n",
    "                generic_filter_coefficients['Offset_Filter']['a'] = highpass_a\n",
    "                generic_filter_coefficients['Offset_Filter']['b'] = highpass_b\n",
    "                \n",
    "                if len(filter_stage_responses) == 0:\n",
    "                    filter_stage_responses = {'Frequency': (LFP_Data['sampling_Frequency'] * 0.5 / np.pi) * highpass_w, 'Offset_Response': 20.0*np.log10(abs(highpass_h))}\n",
    "                else:\n",
    "                    filter_stage_responses['Offset_Response'] = 20.0*np.log10(abs(highpass_h))\n",
    "            \n",
    "            \n",
    "            # Check if the bandpass filter is implemented and calculate filter response if so\n",
    "            if ((filter_stage_key == \"Bandpass_Filter\") and (filter_stage_options[filter_stage_key] == True)):\n",
    "                \n",
    "                # Calculate the bandpass frequency response\n",
    "                bandpass_b, bandpass_a = iir_butter_bandpass(bandpass_lowcut, bandpass_highcut, LFP_Data['sampling_Frequency'], order=bandpass_filter_order)\n",
    "                bandpass_w, bandpass_h = freqz(bandpass_b, bandpass_a, worN=2000)\n",
    "                \n",
    "                # Add the coefficients to the filter coefficient dictionary\n",
    "                generic_filter_coefficients['Bandpass_Filter'] = {}\n",
    "                generic_filter_coefficients['Bandpass_Filter']['a'] = bandpass_a\n",
    "                generic_filter_coefficients['Bandpass_Filter']['b'] = bandpass_b\n",
    "                \n",
    "                if len(filter_stage_responses) == 0:\n",
    "                    filter_stage_responses = {'Frequency': (LFP_Data['sampling_Frequency'] * 0.5 / np.pi) * bandpass_w, 'Bandpass_Response': 20.0*np.log10(abs(bandpass_h))}\n",
    "                else:\n",
    "                    filter_stage_responses['Bandpass_Response'] = 20.0*np.log10(abs(bandpass_h))\n",
    "                    \n",
    "            # Check if the lowpass filter is implemented and calculate filter response if so\n",
    "            if ((filter_stage_key == \"Smoothing_Filter\") and (filter_stage_options[filter_stage_key] == True)):\n",
    "                \n",
    "                # Calculate the smoothing filter frequency response\n",
    "                lowpass_b, lowpass_a = iir_butter_lowpass(lowpass_cutoff, LFP_Data['sampling_Frequency'], order=lowpass_filter_order)\n",
    "                lowpass_w, lowpass_h = freqz(lowpass_b, lowpass_a, worN=2000)\n",
    "                \n",
    "                # Add the coefficients to the filter coefficient dictionary\n",
    "                generic_filter_coefficients['Smoothing_Filter'] = {}\n",
    "                generic_filter_coefficients['Smoothing_Filter']['a'] = lowpass_a\n",
    "                generic_filter_coefficients['Smoothing_Filter']['b'] = lowpass_b\n",
    "                \n",
    "                if len(filter_stage_responses) == 0:\n",
    "                    filter_stage_responses = {'Frequency': (LFP_Data['sampling_Frequency'] * 0.5 / np.pi) * lowpass_w, 'Smoothing_Response': 20.0*np.log10(abs(lowpass_h))}\n",
    "                else:\n",
    "                    filter_stage_responses['Smoothing_Response'] = 20.0*np.log10(abs(lowpass_h))\n",
    "            \n",
    "            # Convert the magnitude response dictionary to a dataframe\n",
    "            filter_stage_responses = pd.DataFrame(data=filter_stage_responses)\n",
    "\n",
    "# Dictionary for storing the signal from each part of the signal processing chain\n",
    "signal_Chain_Data = {}            \n",
    "\n",
    "# scaling factor for plotting the labels in plots\n",
    "plot_labels_scaling_factor = 1 \n",
    "\n",
    "def run_Signal_Processing_Chain(event):\n",
    "    # Variables for tracking the filter stages used\n",
    "    global filter_stage_options\n",
    "    \n",
    "    # Variable for tracking the filter implementation used\n",
    "    global filter_DyNeuMo_Implementation \n",
    "    \n",
    "    # Define string for specifying the flags for the filter stages to be implemented\n",
    "    global filter_configuration_string\n",
    "    global LFP_Data\n",
    "    global generic_filter_coefficients\n",
    "    \n",
    "    # Raw signal should be converted to ADC steps prior to filtering\n",
    "    global signal_Chain_Data\n",
    "    signal_Chain_Data = {}\n",
    "    \n",
    "    # scaling factor for plotting the labels in plots\n",
    "    global plot_labels_scaling_factor\n",
    "    \n",
    "    # Conversion factor for converting volts to adc steps\n",
    "    variable_gain_factor = 1\n",
    "    adc_conversion_factor = 25e-3/(variable_gain_factor * pow(2,16))\n",
    "\n",
    "    # Add the time to the dictionary for the signal chain\n",
    "    signal_Chain_Data[\"Time\"] = LFP_Data['raw_LFP_Data']['Time']\n",
    "    \n",
    "    # For signal chain the input signal should be the raw signal converted from volts to adc steps - round to closest adc step\n",
    "    filter_stage_output_signal = np.round(LFP_Data['raw_LFP_Data']['Voltage']/adc_conversion_factor)\n",
    "    signal_Chain_Data[\"Input\"] = filter_stage_output_signal\n",
    "    \n",
    "    # Convert from dictionary to dataframe\n",
    "    signal_Chain_Data = pd.DataFrame(data=signal_Chain_Data)\n",
    "    \n",
    "    # Now check whether the implementation is generic or for the DyNeuMo\n",
    "    if filter_DyNeuMo_Implementation == True:\n",
    "        \n",
    "        # Build the string to specify the filter configuration for Robert's program\n",
    "        pass\n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # Take the ADC steps signal and pass it through each stage of the filter process\n",
    "        # Note- The signal chain is always in this specific order \n",
    "        # 1) Offset Filter\n",
    "        # 2) Bandpass Filter\n",
    "        # 3) Rectifier\n",
    "        # 4) Smoothing Filter\n",
    "        \n",
    "        # Check if the offset filter is implemented and calculate filter response if so\n",
    "        if (filter_stage_options[\"Offset_Filter\"] == True):\n",
    "                \n",
    "            # Filter the signal using the precalculated filter coefficients \n",
    "            filter_stage_output_signal = lfilter(generic_filter_coefficients['Offset_Filter']['b'], \n",
    "                                                 generic_filter_coefficients['Offset_Filter']['a'], \n",
    "                                                 filter_stage_output_signal)\n",
    "            \n",
    "            # Store the output from the filter stage\n",
    "            signal_Chain_Data[\"Offset_Filter\"] = filter_stage_output_signal\n",
    "            \n",
    "        # Check if the bandpass filter is implemented and calculate filter response if so\n",
    "        if (filter_stage_options[\"Bandpass_Filter\"] == True):\n",
    "                \n",
    "            # Filter the signal using the precalculated filter coefficients \n",
    "            filter_stage_output_signal = lfilter(generic_filter_coefficients['Bandpass_Filter']['b'], \n",
    "                                                 generic_filter_coefficients['Bandpass_Filter']['a'], \n",
    "                                                 filter_stage_output_signal)\n",
    "            \n",
    "            # Store the output from the filter stage\n",
    "            signal_Chain_Data[\"Bandpass_Filter\"] = filter_stage_output_signal        \n",
    "            \n",
    "        # Check if the rectifier is implemented and calculate filter response if so\n",
    "        if (filter_stage_options[\"Rectifier\"] == True):\n",
    "                \n",
    "            # Rectify the signal\n",
    "            filter_stage_output_signal = np.abs(filter_stage_output_signal)\n",
    "            \n",
    "            # Store the output from the filter stage\n",
    "            signal_Chain_Data[\"Rectifier\"] = filter_stage_output_signal        \n",
    "            \n",
    "        if (filter_stage_options[\"Smoothing_Filter\"] == True):\n",
    "                \n",
    "            # Filter the signal using the precalculated filter coefficients \n",
    "            filter_stage_output_signal = lfilter(generic_filter_coefficients['Smoothing_Filter']['b'], \n",
    "                                                 generic_filter_coefficients['Smoothing_Filter']['a'], \n",
    "                                                 filter_stage_output_signal)\n",
    "            \n",
    "            # Store the output from the filter stage\n",
    "            signal_Chain_Data[\"Smoothing_Filter\"] = filter_stage_output_signal\n",
    "        \n",
    "        # Now store the output of the signal chain as column in dataframe\n",
    "        signal_Chain_Data[\"Output\"] = filter_stage_output_signal\n",
    "        \n",
    "        # Also store the labels of the signal chain as the final column in dataframe\n",
    "        signal_Chain_Data[\"Labels\"] = LFP_Data['raw_LFP_Data']['Data_Labels']\n",
    "        plot_labels_scaling_factor = (np.max(filter_stage_output_signal) + (0.1*np.max(filter_stage_output_signal)))\n",
    "        signal_Chain_Data[\"Plotting_Labels\"] = plot_labels_scaling_factor * signal_Chain_Data[\"Labels\"] \n",
    "        \n",
    "# Link button click to building the specified filters\n",
    "build_Filters_Button.on_click(build_Filters)\n",
    "\n",
    "# Link button click to running the signal chain\n",
    "run_Signal_Chain_Button.on_click(run_Signal_Processing_Chain)\n",
    "\n",
    "filter_tool = pn.Column(pn.Row('####Offset Filter', offset_Filter_Group, offset_Fc_select), pn.Row('####Bandpass Filter', bandpass_Filter_Group,  bandpass_Fc_Range_Slider), pn.Row('####Rectifier', rectification_Group), pn.Row('####Smoothing Filter', smoothing_Filter_Group,  smoothing_Fc_Slider), pn.Row('####Build Filters', build_Filter_Group, build_Filters_Button, run_Signal_Chain_Button))\n",
    "filter_design_tool_card = pn.Card(filter_tool, title='Filter Design Tool', background='WhiteSmoke')\n",
    "filter_design_tool_card\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5bab9",
   "metadata": {},
   "source": [
    "# Step 6 - Filter Response Viewer\n",
    "\n",
    "Run the cell below to view the magnitude responses for the enabled filters in the signal processing chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ae314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the magnitude response plots\n",
    "filter_magnitude_response_plots = (hv.Curve(filter_stage_responses, 'Frequency', 'Offset_Response', label='Offset') * hv.Curve(filter_stage_responses, 'Frequency', 'Bandpass_Response', label='Bandpass') * hv.Curve(filter_stage_responses, 'Frequency', 'Smoothing_Response', label='Smoothing')).opts(title='Filter Magnitude Response', ylabel='Magnitude (dB)', xlabel='Frequency (Hz)', height=400, width=600, fontscale=1.5)\n",
    "filter_response_viewer_card = pn.Card(filter_magnitude_response_plots, title='Filter Response Viewer', background='WhiteSmoke')\n",
    "filter_response_viewer_card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a5824",
   "metadata": {},
   "source": [
    "# Step 7 - Signal Chain Output Viewer\n",
    "\n",
    "Run the cell below to generate figures demonstrating the output of each stage in the signal processing chain. Click on the tabs above the plot to view each stage. The output tab demonstrates the output of the full signal processing chain with the user specified labels from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traces for the signal processing chain output and user defined labels\n",
    "event_Labels_Trace = hv.Curve(signal_Chain_Data, 'Time', 'Plotting_Labels').opts(ylabel='ADC Steps', xlabel='Time (s)', title='Signal Processing Chain Output', color='red')\n",
    "signal_Chain_Output_Trace = hv.Curve(signal_Chain_Data, 'Time', 'Output').opts(ylabel='ADC Steps', xlabel='Time (s)', title='Signal Processing Chain Output')\n",
    "\n",
    "# Generate the plots of each stage output of the signal processing chain\n",
    "signal_Processing_Chain_Plots = pn.Tabs(\n",
    "        ('Input', hv.Curve(signal_Chain_Data, 'Time', 'Input').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Input Signal', height=300, width=900)),\n",
    "        ('Offset', hv.Curve(signal_Chain_Data, 'Time', 'Offset_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Offset Stage Output', height=300, width=900)),\n",
    "        ('Bandpass', hv.Curve(signal_Chain_Data, 'Time', 'Bandpass_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Bandpass Stage Output', height=300, width=900)),\n",
    "        ('Rectifier', hv.Curve(signal_Chain_Data, 'Time', 'Rectifier').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Rectifier Stage Output', height=300, width=900)),\n",
    "        ('Smoothing', hv.Curve(signal_Chain_Data, 'Time', 'Smoothing_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Smoothing Stage Output', height=300, width=900)),\n",
    "        ('Output', (signal_Chain_Output_Trace * event_Labels_Trace).opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Output Signal and True Labels', height=300, width=900))\n",
    "    )\n",
    "\n",
    "signal_Chain_Output_Viewer_Card = pn.Card(signal_Processing_Chain_Plots, title='Signal Chain Stage Output Viewer', background='WhiteSmoke')\n",
    "signal_Chain_Output_Viewer_Card\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cc5f2",
   "metadata": {},
   "source": [
    "## Step 8 - ROC Curve Tool (Classifier Threshold Selection Tool)\n",
    "\n",
    "Run the next cell below to generate the tool for selecting the classifier threshold and debounce parameter. Double-click on a point on the ROC curve for which you want to use as your threshold. Next, you next select a debounce value that you want to implement from the integer slider below the ROC curve. Following this you should then click the 'Build Classifier' button to build the classifier with the specified threshold and debounce period. The performance metrics text on the right-hand side of the figure will be updated to summarize the predicted performance of the classifier with the specified debounce period. Once you are satisfied with the classifier performance reported you should then run the final cell below to generate a figure of the predicted classifier output for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold vector with a fine grid\n",
    "min_envelope_value = np.min(signal_Chain_Data[\"Output\"])\n",
    "min_threshold = int(np.round(min_envelope_value - (0.1 * min_envelope_value)))\n",
    "\n",
    "# Makes no sense having a negative threshold with the rectifier on\n",
    "if ((filter_stage_options[\"Rectifier\"] == True) and (min_threshold < 0)):\n",
    "    min_threshold = 0\n",
    "\n",
    "max_envelope_value = np.max(signal_Chain_Data[\"Output\"])\n",
    "max_threshold = int(np.round(max_envelope_value + (0.1 * max_envelope_value)))\n",
    "potential_Thresholds = np.round(np.linspace(min_threshold, max_threshold, 1000))\n",
    "\n",
    "debounce_duration = 0.1\n",
    "debounce_duration_samples = int(debounce_duration * LFP_Data['sampling_Frequency'])\n",
    "\n",
    "# Create an array for the classifications of each threshold\n",
    "classRes = np.zeros((len(signal_Chain_Data[\"Output\"]), len(potential_Thresholds)))\n",
    "\n",
    "# Increment through the different thresholds and make an initial check whether \n",
    "# the value is above or below the threshold. A class of 1 represents the alpha state\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "\n",
    "    # Get the threshold value\n",
    "    threshold_value = potential_Thresholds[j]\n",
    "    \n",
    "    # Check which signal values are above the threshold\n",
    "    positive_classification_ids = np.where(signal_Chain_Data[\"Output\"] >= threshold_value)[0]\n",
    "    classRes[positive_classification_ids, j] = 1\n",
    "    \n",
    "#Now compare classifications for each threshold with the actual labels\n",
    "truth = signal_Chain_Data[\"Labels\"]\n",
    "\n",
    "#               |         Classifier output\n",
    "#   True state  |  Alpha state = 0  |  Alpha state = 1  \n",
    "# ------------------------------------------------------\n",
    "#   Eyes open   | True Negative  TN | False Positive FP\n",
    "#  Eyes closed  | False Negative FN | True Positive  TP\n",
    "\n",
    "# Calculate TP, TN, FP, FN values\n",
    "tp = np.zeros(len(potential_Thresholds))\n",
    "tn = np.zeros(len(potential_Thresholds))\n",
    "fp = np.zeros(len(potential_Thresholds))\n",
    "fn = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Loop over the thresholds and calculate the corresponding values\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "    \n",
    "    # For postive classifications, check the number of true positives and false negatives\n",
    "    positive_classification_ids = np.where(truth == 1)[0]\n",
    "    \n",
    "    # Total True Positives - \n",
    "    true_positives_ids = np.where(classRes[positive_classification_ids, j] == 1)[0]  \n",
    "    tp[j] = len(true_positives_ids)\n",
    "    \n",
    "    # Total False Negatives - \n",
    "    false_negative_ids = np.where(classRes[positive_classification_ids, j] == 0)[0]\n",
    "    fn[j] = len(false_negative_ids)\n",
    "    \n",
    "    # For negative classifications, check the number of true negatives and false positives\n",
    "    negative_classification_ids = np.where(truth == 0)[0]\n",
    "    \n",
    "    # Total True Negatives - \n",
    "    true_negatives_ids = np.where(classRes[negative_classification_ids, j] == 0)[0]  \n",
    "    tn[j] = len(true_negatives_ids)\n",
    "    \n",
    "    # Total False Positives - \n",
    "    false_positive_ids = np.where(classRes[negative_classification_ids, j] == 1)[0]\n",
    "    fp[j] = len(false_positive_ids)\n",
    "\n",
    "\n",
    "# Create true positive rate (TPR) and false positive rate (TPR) vectors\n",
    "tpr = np.zeros(len(potential_Thresholds))\n",
    "fpr = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Create precision and recall vectors\n",
    "precision = np.zeros(len(potential_Thresholds))\n",
    "recall = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Now find the true positive rate and false positive rate for each threshold\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "    # True positive rate (sensitivity)\n",
    "    # i.e. probability that a true positive is classified as positive\n",
    "    # TPR = TP / (TP + FN)\n",
    "    if tp[j] == 0:\n",
    "        tpr[j] = 0\n",
    "    else:\n",
    "        tpr[j] = tp[j] / (tp[j] + fn[j])\n",
    "\n",
    "    # False positive rate (1-specificity)\n",
    "    # probability that a true negative is classified as positive\n",
    "    # FPR = FP / (FP + TN)\n",
    "    if fp[j] == 0:\n",
    "        fpr[j] = 0\n",
    "    else:\n",
    "        fpr[j] = fp[j] / (fp[j] + tn[j])\n",
    "    \n",
    "    # Precision and Recall - \n",
    "    # precision = TP / (TP + FP) \n",
    "    if tp[j] == 0:\n",
    "        precision[j] = 0\n",
    "    else:\n",
    "        precision[j] = tp[j] / (tp[j] + fp[j])\n",
    "    \n",
    "    # Recall - \n",
    "    # recall = TP / (TP + FN)\n",
    "    if tp[j] == 0:\n",
    "        recall[j] = 0\n",
    "    else:\n",
    "        recall[j] = tp[j] / (tp[j] + fn[j])\n",
    "\n",
    "# ROC curve dataset\n",
    "ROC_ds = hv.Dataset((fpr, tpr, potential_Thresholds), ['FPR', 'TPR'], 'Threshold')\n",
    "\n",
    "# Precision-Recall curve dataset\n",
    "precision_recall_ds = hv.Dataset((precision, recall, potential_Thresholds), ['Precision', 'Recall'], 'Threshold')\n",
    "\n",
    "# Plot the ROC Curve\n",
    "ROC_Curve_data = {'FPR': fpr, 'TPR': tpr, 'Threshold': potential_Thresholds}\n",
    "ROC_dataframe = pd.DataFrame(data=ROC_Curve_data)\n",
    "\n",
    "# Plot for the ROC curve\n",
    "ROC_Trace = hv.Curve(ROC_dataframe, 'FPR', 'TPR').opts(tools=['hover', 'tap'], line_dash='solid')\n",
    "naive_Trace = hv.Curve(ROC_dataframe, 'FPR', 'FPR').opts(line_dash='dashed')\n",
    "\n",
    "# Stream for detecting double-clicks\n",
    "ROC_click_Stream = hv.streams.DoubleTap(source=ROC_Trace, x=-10, y=-10, transient=True)\n",
    "\n",
    "# Threshold of user selected threshold for classifier\n",
    "ROC_selected_threshold = -10\n",
    "\n",
    "# Define a radio group for determining the characteristic to use for selecting the classifier threshold\n",
    "classifier_threshold_characteristic_radio_group = pn.widgets.RadioButtonGroup(\n",
    "    name='Classifier Characteristic Radio Group', options=['Receiver-Operator', 'Precision-Recall'], button_type='success')\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def mark_ROC_Threshold(x, y):\n",
    "    \n",
    "    # Define that the selected threshold is global\n",
    "    global ROC_selected_threshold\n",
    "    \n",
    "    # Highlight the threshold as a horizontal line\n",
    "    y_threshold_line = hv.HLine(y).opts(color='black', line_dash='dashed')\n",
    "    \n",
    "    # Find the closest value to the y horizontal line\n",
    "    ROC_y_threshold_id = (ROC_dataframe['TPR'] - y).abs().argsort()[0]\n",
    "    \n",
    "    # Set the Vertical line as the closest TPR to the intersection point\n",
    "    x_threshold_value = ROC_dataframe['FPR'][ROC_y_threshold_id]\n",
    "    x_threshold_line = hv.VLine(x_threshold_value).opts(color='black', line_dash='dashed')\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection_point = hv.Scatter((x_threshold_value, y)).opts(color='red', size=8)\n",
    "    \n",
    "    # Update the selected threshold\n",
    "    ROC_selected_threshold = ROC_dataframe['Threshold'][ROC_y_threshold_id]\n",
    "    \n",
    "    # Text to indicate the Threshold value\n",
    "    text = hv.Text(x_threshold_value+0.05, y, \"Threshold = {:} ADC Steps\".format(int(ROC_selected_threshold)), halign='left', valign='bottom')\n",
    "    \n",
    "    return x_threshold_line * y_threshold_line * intersection_point * text\n",
    "\n",
    "# Declare pointer stream initializing at (0, 0) and linking to ROC_Trace\n",
    "ROC_pointer_Stream = streams.PointerXY(x=0, y=0, source=ROC_Trace)\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def hover_ROC_Threshold(x, y):\n",
    "    \n",
    "    # Highlight the threshold as a horizontal line\n",
    "    y_threshold_line = hv.HLine(y).opts(color='black', line_dash='solid')\n",
    "    \n",
    "    # Find the closest value to the y horizontal line\n",
    "    ROC_y_threshold_id = (ROC_dataframe['TPR'] - y).abs().argsort()[0]\n",
    "    \n",
    "    # Set the Vertical line as the closest TPR to the intersection point\n",
    "    x_threshold_value = ROC_dataframe['FPR'][ROC_y_threshold_id]\n",
    "    x_threshold_line = hv.VLine(x_threshold_value).opts(color='black', line_dash='solid')\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection_point = hv.Scatter((x_threshold_value, y)).opts(color='black', size=6)\n",
    "    \n",
    "    # Update the selected threshold\n",
    "    selected_threshold = ROC_dataframe['Threshold'][ROC_y_threshold_id]\n",
    "    \n",
    "    # Text to indicate the Threshold value\n",
    "    text = hv.Text(x_threshold_value+0.05, y, \"Threshold = {:} ADC Steps\".format(int(selected_threshold)), halign='left', valign='bottom')\n",
    "    \n",
    "    return x_threshold_line * y_threshold_line * intersection_point * text\n",
    "\n",
    "# List for debounced classifier states\n",
    "debounced_classifier_states = []\n",
    "\n",
    "# Dictionary for debounced classifier performance results\n",
    "classifier_Performance_Results = {}\n",
    "\n",
    "# Function definition for building the classifier based on selected threshold and debounce\n",
    "def build_Classifier(event):\n",
    "    \n",
    "    # Need access to the sampling frequency \n",
    "    global LFP_Data\n",
    "    Fs = LFP_Data['sampling_Frequency']\n",
    "    \n",
    "    # Define that the selected threshold is global\n",
    "    global ROC_selected_threshold\n",
    "    \n",
    "    # Have access to the signal chain data for the classifier\n",
    "    global signal_Chain_Data\n",
    "    \n",
    "    # Define the truth signal\n",
    "    truth = signal_Chain_Data['Labels']\n",
    "    \n",
    "    # Define variables for calculating the classifier performance\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    # Define variable for tracking the current classifier state and new list for the classifier with debounce classifications\n",
    "    current_classifier_state = 0\n",
    "    enable_debounce = False\n",
    "    global debounced_classifier_states\n",
    "    debounced_classifier_states = []\n",
    "    \n",
    "    # Debounced duration\n",
    "    debounce_Duration_in_Samples = int(Fs * debounce_Slider.value)\n",
    "    debounce_Countdown_in_Samples = 0\n",
    "    \n",
    "    # Classifier performance metrics dictionary \n",
    "    global classifier_Performance_Results\n",
    "\n",
    "    # Define variable for tracking the current classification state\n",
    "    for sample in signal_Chain_Data['Output']:\n",
    "\n",
    "        # Debounce is not triggered yet \n",
    "        if ((enable_debounce == False) or (debounce_Duration_in_Samples == 0)):\n",
    "\n",
    "            # Check if classifier output remained above threshold since last classification\n",
    "            if ((sample >= ROC_selected_threshold) and (current_classifier_state==1)):\n",
    "\n",
    "                    # Classifier state will stay the same at 1\n",
    "                    current_classifier_state = 1\n",
    "\n",
    "                    # Append the classification to the classifier states list\n",
    "                    debounced_classifier_states.append(current_classifier_state)\n",
    "\n",
    "                    # keep the debounce period off\n",
    "                    enable_debounce = False\n",
    "\n",
    "            # Check if classifier output went above threshold since last classification\n",
    "            elif ((sample >= ROC_selected_threshold) and (current_classifier_state==0)):\n",
    "\n",
    "                    # Classifier state will stay the same at 1\n",
    "                    current_classifier_state = 1\n",
    "\n",
    "                    # Append the classification to the classifier states list\n",
    "                    debounced_classifier_states.append(current_classifier_state)\n",
    "\n",
    "                    # Trigger the debounce period\n",
    "                    enable_debounce = True\n",
    "                    debounce_Countdown_in_Samples = debounce_Duration_in_Samples\n",
    "\n",
    "            # Check if classifier output remained below threshold since last classification\n",
    "            if ((sample < ROC_selected_threshold) and (current_classifier_state==0)):\n",
    "\n",
    "                    # Classifier state will stay the same at 0\n",
    "                    current_classifier_state = 0\n",
    "\n",
    "                    # Append the classification to the classifier states list\n",
    "                    debounced_classifier_states.append(current_classifier_state)\n",
    "\n",
    "                    # keep the debounce period off\n",
    "                    enable_debounce = False\n",
    "\n",
    "            # Check if classifier output went below threshold since last classification\n",
    "            elif ((sample < ROC_selected_threshold) and (current_classifier_state==1)):\n",
    "\n",
    "                    # Classifier state will stay the same at 0\n",
    "                    current_classifier_state = 0\n",
    "\n",
    "                    # Append the classification to the classifier states list\n",
    "                    debounced_classifier_states.append(current_classifier_state)\n",
    "\n",
    "                    # Trigger the debounce period\n",
    "                    enable_debounce = True\n",
    "                    debounce_Countdown_in_Samples = debounce_Duration_in_Samples\n",
    "\n",
    "        # Debounce is triggered yet \n",
    "        else:\n",
    "\n",
    "            # Countdown the samples until debounce is switched off\n",
    "            if debounce_Countdown_in_Samples > 0:\n",
    "\n",
    "                # Append the classification to the classifier states list\n",
    "                debounced_classifier_states.append(current_classifier_state)\n",
    "\n",
    "                # Decrement the counter\n",
    "                debounce_Countdown_in_Samples = debounce_Countdown_in_Samples - 1\n",
    "\n",
    "                # Check if the debounce period will be over for next sample\n",
    "                if debounce_Countdown_in_Samples == 0:\n",
    "\n",
    "                    # Switch off the debounce for next sample\n",
    "                    enable_debounce = False\n",
    "\n",
    "    # Convert the classifier outputs to numpy array\n",
    "    debounce_ClassRes = np.array(debounced_classifier_states)\n",
    "\n",
    "    # Now calculate the updated classifier performance metrics \n",
    "    # For postive classifications, check the number of true positives and false negatives\n",
    "    positive_classification_ids = np.where(truth == 1)[0]\n",
    "\n",
    "    # Total True Positives - \n",
    "    true_positives_ids = np.where(debounce_ClassRes[positive_classification_ids] == 1)[0]  \n",
    "    tp = len(true_positives_ids)\n",
    "\n",
    "    # Total False Negatives - \n",
    "    false_negative_ids = np.where(debounce_ClassRes[positive_classification_ids] == 0)[0]\n",
    "    fn = len(false_negative_ids)\n",
    "\n",
    "    # For negative classifications, check the number of true negatives and false positives\n",
    "    negative_classification_ids = np.where(truth == 0)[0]\n",
    "\n",
    "    # Total True Negatives - \n",
    "    true_negatives_ids = np.where(debounce_ClassRes[negative_classification_ids] == 0)[0]  \n",
    "    tn = len(true_negatives_ids)\n",
    "\n",
    "    # Total False Positives - \n",
    "    false_positive_ids = np.where(debounce_ClassRes[negative_classification_ids] == 1)[0]\n",
    "    fp = len(false_positive_ids)\n",
    "\n",
    "    # Now calculate the updated classifier metrics\n",
    "    # True positive rate (sensitivity)\n",
    "    # i.e. probability that a true positive is classified as positive\n",
    "    # TPR = TP / (TP + FN)\n",
    "    if tp == 0:\n",
    "        tpr = 0\n",
    "    else:\n",
    "        tpr = tp / (tp + fn)\n",
    "\n",
    "    # False positive rate (1-specificity)\n",
    "    # probability that a true negative is classified as positive\n",
    "    # FPR = FP / (FP + TN)\n",
    "    if fp == 0:\n",
    "        fpr = 0\n",
    "    else:\n",
    "        fpr = fp / (fp + tn)\n",
    "\n",
    "    # Precision and Recall - \n",
    "    # precision = TP / (TP + FP) \n",
    "    if tp == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "\n",
    "    # Recall - \n",
    "    # recall = TP / (TP + FN)\n",
    "    if tp == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "    # Now save the classifier result metrics\n",
    "    classifier_Performance_Results = {'Sensitivity' : tpr,\n",
    "                                     'Specificity' : fpr,\n",
    "                                     'Precision' : precision,\n",
    "                                     'Recall' : recall}\n",
    "\n",
    "    # Update the text widgets with the performance values as percentages\n",
    "    classifier_Sensitivity_Performance_text.value = \" {:.2f} %\".format(classifier_Performance_Results['Sensitivity']*100)\n",
    "    classifier_Specificity_Performance_text.value = \" {:.2f} %\".format(classifier_Performance_Results['Specificity']*100)\n",
    "    classifier_Precision_Performance_text.value = \" {:.2f} %\".format(classifier_Performance_Results['Precision']*100)\n",
    "    classifier_Recall_Performance_text.value = \" {:.2f} %\".format(classifier_Performance_Results['Recall']*100)\n",
    "    \n",
    "    # Add debounced classifier output to the signal chain dataframe\n",
    "    plot_labels_scaling_factor = (np.max(signal_Chain_Data['Output']) + (0.1*np.max(signal_Chain_Data['Output'])))\n",
    "    signal_Chain_Data['Classifier_Labels'] = debounce_ClassRes\n",
    "    signal_Chain_Data['Plotting_Classifier_Labels'] = plot_labels_scaling_factor * debounce_ClassRes\n",
    "    \n",
    "# Set up dynamic map for tracking double-clicking on the plot\n",
    "ROC_Threshold_Double_Click_dmap = hv.DynamicMap(mark_ROC_Threshold, streams=[ROC_click_Stream])\n",
    "ROC_Threshold_Hover_dmap = hv.DynamicMap(hover_ROC_Threshold, streams=[ROC_pointer_Stream])\n",
    "\n",
    "# Make widgets for setting the debounce\n",
    "debounce_Slider = pn.widgets.IntSlider(\n",
    "    name='Debounce Duration:', start=0, end=10, step=1, value=0, \n",
    "    format=PrintfTickFormatter(format='%.0f s'))\n",
    "\n",
    "build_Classifier_Button = pn.widgets.Button(name='Build Classifier', button_type='primary', width=100, align='end')\n",
    "\n",
    "# Link button click to running the generating the updated classifier output\n",
    "build_Classifier_Button.on_click(build_Classifier)\n",
    "\n",
    "# Make static text to report classifier performance\n",
    "classifier_Performance_text = pn.widgets.StaticText(name='Classifier Performance Metrics:', value='')\n",
    "classifier_Sensitivity_Performance_text = pn.widgets.StaticText(name='Sensitivity = ', value='')\n",
    "classifier_Specificity_Performance_text = pn.widgets.StaticText(name='Specificity = ', value='')\n",
    "classifier_Precision_Performance_text = pn.widgets.StaticText(name='Precision = ', value='')\n",
    "classifier_Recall_Performance_text = pn.widgets.StaticText(name='Recall = ', value='')\n",
    "\n",
    "# Plot for the ROC curve - \n",
    "ROC_Figure = (ROC_Trace * ROC_Threshold_Double_Click_dmap * naive_Trace).opts(fontscale=1.5, height=450, width=550, title='ROC Curve', xlabel='False Positive Rate (FPR)', ylabel='True Positive Rate (TPR)', xlim=(0,1), ylim=(0,1))\n",
    "threshold_Selection_Tool = pn.Column(pn.Row(ROC_Figure), pn.Row('####Debounce Duration', debounce_Slider, build_Classifier_Button))\n",
    "classifier_Performance_Text_Widgets = pn.Column(classifier_Performance_text, classifier_Sensitivity_Performance_text, classifier_Specificity_Performance_text, classifier_Precision_Performance_text, classifier_Recall_Performance_text)\n",
    "threshold_Selection_Tool_Card = pn.Card(pn.Row(threshold_Selection_Tool, classifier_Performance_Text_Widgets), title='Threshold Selection Tool', background='WhiteSmoke')\n",
    "\n",
    "threshold_Selection_Tool_Card\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa0112",
   "metadata": {},
   "source": [
    "## Step 9 - Classifier Performance Viewer \n",
    "\n",
    "Run the final cell below to generate figures of the predicted classifier performance along with the previous signals from each of the signal processing chain outputs.\n",
    "\n",
    "Exporting of the configuration to file is still to be debugged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b44a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traces for the signal processing chain output and user defined labels\n",
    "classifier_Labels_Trace = hv.Curve(signal_Chain_Data, 'Time', 'Plotting_Classifier_Labels').opts(ylabel='ADC Steps', xlabel='Time (s)', title='Predicted Classifier Labels')\n",
    "selected_threshold_HLine = hv.HLine(ROC_selected_threshold).opts(color='black', line_dash='dashed')\n",
    "\n",
    "# Generate the plots of each stage output of the signal processing chain\n",
    "signal_Processing_Chain_with_Classifier_Plots = pn.Tabs(\n",
    "        ('Predicted Classifier Labels', (signal_Chain_Output_Trace * event_Labels_Trace * classifier_Labels_Trace * selected_threshold_HLine).opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Output Signal and True Labels', height=300, width=900)),\n",
    "        ('Input', hv.Curve(signal_Chain_Data, 'Time', 'Input').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Input Signal', height=300, width=900)),\n",
    "        ('Offset', hv.Curve(signal_Chain_Data, 'Time', 'Offset_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Offset Stage Output', height=300, width=900)),\n",
    "        ('Bandpass', hv.Curve(signal_Chain_Data, 'Time', 'Bandpass_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Bandpass Stage Output', height=300, width=900)),\n",
    "        ('Rectifier', hv.Curve(signal_Chain_Data, 'Time', 'Rectifier').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Rectifier Stage Output', height=300, width=900)),\n",
    "        ('Smoothing', hv.Curve(signal_Chain_Data, 'Time', 'Smoothing_Filter').opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Smoothing Stage Output', height=300, width=900)),\n",
    "        ('Output', (signal_Chain_Output_Trace * event_Labels_Trace).opts(fontscale=1.5, ylabel='ADC Steps', xlabel='Time (s)', title='Output Signal and True Labels', height=300, width=900))    \n",
    "    )\n",
    "\n",
    "# Button for exporting the configuration file if happy - not implemented yet\n",
    "export_Configuration_Button = pn.widgets.Button(name='Export Configuration', button_type='primary', width=100)\n",
    "\n",
    "configuration_Viewer_Tool = pn.Column(signal_Processing_Chain_with_Classifier_Plots, export_Configuration_Button)\n",
    "Classifier_Output_Viewer_Card = pn.Card(configuration_Viewer_Tool, title='Classifer Output Viewer', background='WhiteSmoke')\n",
    "Classifier_Output_Viewer_Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd57f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
